{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":66960,"status":"ok","timestamp":1661832861506,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"NzLpkiDD71nL","outputId":"52a847ca-58ae-4dea-ead7-26e943772f69"},"outputs":[],"source":["!pip install tf-nightly"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1040,"status":"ok","timestamp":1661830999557,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"vocLIwgsmWCo","outputId":"664999e0-55a7-4a70-d3a4-07a884dc5db2"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/validation\n","/content\n"]}],"source":["%cd validation\n","!mkdir clean\n","!mkdir down_grade\n","!mv set14-downgraded/* down_grade\n","!mv set5-downgraded/* down_grade\n","!mv Set5/* clean\n","!mv Set14/* clean\n","%cd .."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1661830999558,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"ak9fSnlgnCGe"},"outputs":[],"source":["!rm -R /content/validation/set14-downgraded /content/validation/set5-downgraded /content/validation/Set5 /content/validation/Set14 "]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1661830999559,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"-O0pHA8zmHYR","outputId":"d12740df-64d4-4660-b446-4240bfcbab6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/train\n"]}],"source":["%cd /content/train"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":616,"status":"ok","timestamp":1661831000167,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"8RDm-ZRrmGUg"},"outputs":[],"source":["!mkdir train_y\n","!mv General-100/* train_y\n","!mv \"91\"/* train_y"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1661831000167,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"ovUS8HmQWEdn"},"outputs":[],"source":["!rm -R General-100/ \"91\"/"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18402,"status":"ok","timestamp":1661831018559,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"rBslIjLw897G","outputId":"40a707eb-9f1a-4f1a-fca8-9623215e207c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts\n","  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n","  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n","  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n","  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n","Suggested packages:\n","  fonts-noto ghostscript-x imagemagick-doc autotrace cups-bsd | lpr | lprng\n","  enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer povray radiance\n","  sane-utils texlive-base-bin transfig ufraw-batch inkscape libjxr-tools\n","  libwmf0.2-7-gtk poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n","  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n","  fonts-arphic-uming fonts-nanum\n","The following NEW packages will be installed:\n","  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts imagemagick\n","  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n","  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n","  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n","  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n","0 upgraded, 23 newly installed, 0 to remove and 20 not upgraded.\n","Need to get 18.4 MB of archives.\n","After this operation, 66.3 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6-common all 8:6.9.7.4+dfsg-16ubuntu6.13 [60.3 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.13 [1,620 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.13 [292 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.9 [18.6 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.16 [5,093 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.16 [2,265 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.16 [51.3 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6.q16 amd64 8:6.9.7.4+dfsg-16ubuntu6.13 [423 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick amd64 8:6.9.7.4+dfsg-16ubuntu6.13 [14.2 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre-text all 3.5.27.1-8ubuntu0.4 [49.4 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre21 amd64 3.5.27.1-8ubuntu0.4 [561 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwmf0.2-7 amd64 0.2.8.4-12 [150 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3-extra amd64 8:6.9.7.4+dfsg-16ubuntu6.13 [62.3 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnetpbm10 amd64 2:10.0-15.3build1 [58.0 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 netpbm amd64 2:10.0-15.3build1 [1,017 kB]\n","Fetched 18.4 MB in 1s (29.1 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 23.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-droid-fallback.\n","(Reading database ... 155676 files and directories currently installed.)\n","Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n","Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n","Selecting previously unselected package liblqr-1-0:amd64.\n","Preparing to unpack .../01-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n","Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n","Selecting previously unselected package imagemagick-6-common.\n","Preparing to unpack .../02-imagemagick-6-common_8%3a6.9.7.4+dfsg-16ubuntu6.13_all.deb ...\n","Unpacking imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Selecting previously unselected package libmagickcore-6.q16-3:amd64.\n","Preparing to unpack .../03-libmagickcore-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.13_amd64.deb ...\n","Unpacking libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Selecting previously unselected package libmagickwand-6.q16-3:amd64.\n","Preparing to unpack .../04-libmagickwand-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.13_amd64.deb ...\n","Unpacking libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Selecting previously unselected package poppler-data.\n","Preparing to unpack .../05-poppler-data_0.4.8-2_all.deb ...\n","Unpacking poppler-data (0.4.8-2) ...\n","Selecting previously unselected package fonts-noto-mono.\n","Preparing to unpack .../06-fonts-noto-mono_20171026-2_all.deb ...\n","Unpacking fonts-noto-mono (20171026-2) ...\n","Selecting previously unselected package libcupsimage2:amd64.\n","Preparing to unpack .../07-libcupsimage2_2.2.7-1ubuntu2.9_amd64.deb ...\n","Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n","Selecting previously unselected package libijs-0.35:amd64.\n","Preparing to unpack .../08-libijs-0.35_0.35-13_amd64.deb ...\n","Unpacking libijs-0.35:amd64 (0.35-13) ...\n","Selecting previously unselected package libjbig2dec0:amd64.\n","Preparing to unpack .../09-libjbig2dec0_0.13-6_amd64.deb ...\n","Unpacking libjbig2dec0:amd64 (0.13-6) ...\n","Selecting previously unselected package libgs9-common.\n","Preparing to unpack .../10-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.16_all.deb ...\n","Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n","Selecting previously unselected package libgs9:amd64.\n","Preparing to unpack .../11-libgs9_9.26~dfsg+0-0ubuntu0.18.04.16_amd64.deb ...\n","Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n","Selecting previously unselected package ghostscript.\n","Preparing to unpack .../12-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.16_amd64.deb ...\n","Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n","Selecting previously unselected package gsfonts.\n","Preparing to unpack .../13-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n","Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n","Selecting previously unselected package imagemagick-6.q16.\n","Preparing to unpack .../14-imagemagick-6.q16_8%3a6.9.7.4+dfsg-16ubuntu6.13_amd64.deb ...\n","Unpacking imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Selecting previously unselected package imagemagick.\n","Preparing to unpack .../15-imagemagick_8%3a6.9.7.4+dfsg-16ubuntu6.13_amd64.deb ...\n","Unpacking imagemagick (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Selecting previously unselected package libcupsfilters1:amd64.\n","Preparing to unpack .../16-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n","Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n","Selecting previously unselected package libdjvulibre-text.\n","Preparing to unpack .../17-libdjvulibre-text_3.5.27.1-8ubuntu0.4_all.deb ...\n","Unpacking libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n","Selecting previously unselected package libdjvulibre21:amd64.\n","Preparing to unpack .../18-libdjvulibre21_3.5.27.1-8ubuntu0.4_amd64.deb ...\n","Unpacking libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n","Selecting previously unselected package libwmf0.2-7:amd64.\n","Preparing to unpack .../19-libwmf0.2-7_0.2.8.4-12_amd64.deb ...\n","Unpacking libwmf0.2-7:amd64 (0.2.8.4-12) ...\n","Selecting previously unselected package libmagickcore-6.q16-3-extra:amd64.\n","Preparing to unpack .../20-libmagickcore-6.q16-3-extra_8%3a6.9.7.4+dfsg-16ubuntu6.13_amd64.deb ...\n","Unpacking libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Selecting previously unselected package libnetpbm10.\n","Preparing to unpack .../21-libnetpbm10_2%3a10.0-15.3build1_amd64.deb ...\n","Unpacking libnetpbm10 (2:10.0-15.3build1) ...\n","Selecting previously unselected package netpbm.\n","Preparing to unpack .../22-netpbm_2%3a10.0-15.3build1_amd64.deb ...\n","Unpacking netpbm (2:10.0-15.3build1) ...\n","Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n","Setting up imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n","Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n","Setting up poppler-data (0.4.8-2) ...\n","Setting up libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n","Setting up libnetpbm10 (2:10.0-15.3build1) ...\n","Setting up fonts-noto-mono (20171026-2) ...\n","Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n","Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n","Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n","Setting up libjbig2dec0:amd64 (0.13-6) ...\n","Setting up libijs-0.35:amd64 (0.35-13) ...\n","Setting up netpbm (2:10.0-15.3build1) ...\n","Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n","Setting up libwmf0.2-7:amd64 (0.2.8.4-12) ...\n","Setting up libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Setting up libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n","Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n","Setting up libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Setting up imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n","update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n","update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n","update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n","update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n","update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n","update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n","update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n","update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n","update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n","update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n","update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n","update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n","update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n","update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n","update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n","update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n","update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n","update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n","update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n","update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n","update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n","Setting up libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Setting up imagemagick (8:6.9.7.4+dfsg-16ubuntu6.13) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","/content/train/train_y\n","/content/train\n","/content\n"]}],"source":["# Conversion of bmp images to jpg format, it didnt change the quality of the image \n","!sudo apt install imagemagick\n","%cd train_y\n","!mogrify -format jpg *.bmp\n","!rm *.bmp\n","%cd ..\n","%cd .."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":992,"status":"ok","timestamp":1661831019470,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"lVD_tyY-e4b4","outputId":"5fabe37e-9c36-4dc8-ac64-627f827f658d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/validation/clean\n","/content/validation/down_grade\n","/content\n"]}],"source":["%cd /content/validation/clean\n","!mogrify -format jpg *.png\n","!rm *.png\n","%cd /content/validation/down_grade\n","!mogrify -format jpg *.png\n","!rm *.png\n","%cd /content"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3618,"status":"ok","timestamp":1661832891021,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"s6beIgtY8Bl8"},"outputs":[],"source":["import os\n","import io\n","import PIL\n","import tensorflow as tf\n","import numpy as np\n","import cv2\n","from glob import glob\n","import numpy as  np\n","import sys\n","import random\n","from tqdm import tqdm\n","import argparse\n","import matplotlib.pyplot as plt\n","import copy\n","from functools import partial\n","import multiprocessing\n","\n","#Check folder function, if an required folder is not present, then it creates one\n","def check_folder(log_dir):\n","    if not os.path.exists(log_dir):\n","        os.makedirs(log_dir)\n","    return log_dir\n","\n","# Normalizes the image\n","def normalize(images):\n","    return (images.astype(np.float32)/255.0)\n","\n","# Retains the image to color format\n","def denormalize(images):\n","    return np.clip(images*255.0, a_min=0.001, a_max=255.0).astype(np.uint8)\n","\n","# An iterator to read, process and feed images to the network\n","class Trainset_Dispenser():\n","    def __init__(self, data_path, jpeg_quality, patch_size, batch_size):\n","        self.data_path = data_path\n","        self.jpeg_quality = jpeg_quality\n","        self.patch_size = patch_size\n","        self.batch_size = batch_size\n","        self.images_input, self.images_label = self.load_images()\n","\n","    def load_images(self):\n","        #pre-load images. For example, using the train dataset, 800 images will be preloaded on the memory\n","        file_list = glob(os.path.join(self.data_path,\"*.*\"))\n","        input_list = []\n","        label_list = []\n","        for f in tqdm(file_list):\n","            # read image\n","            label = PIL.Image.open(f).convert('RGB')\n","\n","            # compress\n","            buffer = io.BytesIO()\n","            label.save(buffer, format='jpeg', quality=self.jpeg_quality)\n","            input = PIL.Image.open(buffer)\n","\n","            # normalization and appending\n","            input_list.append(normalize(np.array(input)))\n","            label_list.append(normalize(np.array(label)))\n","\n","        return input_list, label_list\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        patches_input = []\n","        patches_label = []\n","        for i in range(self.batch_size):\n","            rand_idx = random.randint(0,len(self.images_label)-1)\n","            crop_y = random.randint(0, self.images_label[rand_idx].shape[0] - self.patch_size-1)\n","            crop_x = random.randint(0, self.images_label[rand_idx].shape[1] - self.patch_size-1)\n","            input_patch = self.images_input[rand_idx][crop_y:crop_y+self.patch_size, crop_x:crop_x+self.patch_size]\n","            label_patch = self.images_label[rand_idx][crop_y:crop_y+self.patch_size, crop_x:crop_x+self.patch_size]\n","            patches_input.append(input_patch)\n","            patches_label.append(label_patch)\n","\n","        patches_input = np.array(patches_input)\n","        patches_label = np.array(patches_label)\n","        return patches_input, patches_label\n","\n","\n","\n","class Testset_Dispenser():\n","    def __init__(self, data_path, jpeg_quality):\n","        self.data_path = data_path\n","        self.jpeg_quality = jpeg_quality\n","        self.images_input, self.images_label = self.load_images()\n","\n","    def load_images(self):\n","        #pre-load images. For example, using the DIV2K dataset, 800 images will be preloaded on the memory\n","        file_list = glob(os.path.join(self.data_path,\"*.*\"))\n","        input_list = []\n","        label_list = []\n","        for f in tqdm(file_list):\n","            # read image\n","            label = PIL.Image.open(f).convert('RGB')\n","\n","            # compress\n","            buffer = io.BytesIO()\n","            label.save(buffer, format='jpeg', quality=self.jpeg_quality)\n","            input = PIL.Image.open(buffer)\n","\n","            # normalization and appending\n","            input_list.append(normalize(np.expand_dims(np.array(input),axis=0)))\n","            label_list.append(normalize(np.expand_dims(np.array(label),axis=0)))\n","\n","        return input_list, label_list\n","\n","    def __iter__(self):\n","        return zip(self.images_input,self.images_label)"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":377,"status":"ok","timestamp":1661835133104,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"A2PS1mMSLiX0"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","\n","\"\"\" =================================================================\n"," ops \n","================================================================= \"\"\"\n","def L1loss(input,target):\n","    #return tf.reduce_sum(tf.reduce_mean(tf.abs(input - target),axis=0))\n","    return tf.reduce_mean(tf.abs(input - target))\n","\n","\n","\n","\n","\"\"\" =================================================================\n"," model blocks\n","================================================================= \"\"\"\n","initializer = tf.initializers.VarianceScaling()\n","\n","def EncoderBlock(x, activation = tf.keras.layers.LeakyReLU(alpha=0.2), nf = 1024):\n","    x = tf.keras.layers.Dense(256, use_bias=True)(x)\n","    x = activation(x)\n","    x = tf.keras.layers.Dense(512, use_bias=True)(x)\n","    x = activation(x)\n","    x = tf.keras.layers.Dense(nf, use_bias=True)(x)\n","    x = activation(x)\n","    return x\n","\n","def DecoderBlock(x, activation = tf.keras.layers.LeakyReLU(alpha=0.2), nf = 1024):\n","    x = tf.keras.layers.Dense(nf, use_bias=True)(x)\n","    x = activation(x)\n","    x = tf.keras.layers.Dense(512, use_bias=True)(x)\n","    x = activation(x)\n","    x = tf.keras.layers.Dense(256, use_bias=True)(x)\n","    x = activation(x)\n","    x = tf.keras.layers.Dense(3, use_bias=True)(x)\n","    x = activation(x)\n","    return x\n","\n","\n","\n","def ConvolutionalUnit(x, structure_type = 'classic', activation = tf.keras.layers.LeakyReLU(alpha=0.2), nf = 1024):\n","    residual = x\n","\n","    if structure_type == \"classic\":\n","        x = tf.keras.layers.Conv2D(nf, 5, strides=1, padding='same', kernel_initializer=initializer, use_bias=True)(x)\n","        x = activation(x)\n","        x = tf.keras.layers.Add()([x, residual])\n","\n","    elif structure_type == \"advanced\":\n","        x = tf.keras.layers.Conv2D(nf, 5, strides=1, padding='same', kernel_initializer=initializer, use_bias=True)(x)\n","        x = activation(x)\n","        x = tf.keras.layers.Conv2D(nf, 5, strides=1, padding='same', kernel_initializer=initializer, use_bias=True)(x)\n","        x = tf.keras.layers.Lambda(lambda x: x * 0.1)(x)\n","        x = tf.keras.layers.Add()([x, residual])\n","\n","    return x\n","\n","\n","def S_Net_progressiveskip(channels = 3, num_metrics=3 , structure_type='classic'):\n","    inputs = tf.keras.layers.Input(shape=[48, 48, channels])\n","    encoder = EncoderBlock(inputs)\n","    convolution_units = [ConvolutionalUnit(encoder)]\n","    for _ in range(1, num_metrics):\n","        convolution_units.append(ConvolutionalUnit( convolution_units[-1], structure_type = structure_type))\n","\n","    decoders = []\n","    for e,cu in enumerate(convolution_units):\n","        decoders.append(tf.keras.layers.Add()([DecoderBlock(cu), inputs if e == 0 else decoders[-1]]))\n","\n","    #return = [tf.keras.Model(inputs=[inputs], outputs=[dec]) for dec in decoders]\n","    return tf.keras.Model(inputs=[inputs], outputs=decoders)"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":385,"status":"ok","timestamp":1661835135235,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"sZ7maBZAHOYa"},"outputs":[],"source":["import sys\n","sys.path.append('../') #root path\n","from functools import partial\n","\n","class Model_Train():\n","    def __init__(self, summary_dir, num_metrics, checkpoint_dir, learning_rate, min_learning_rate):\n","        self.step = tf.Variable(0,dtype=tf.int64)\n","        self.num_metrics = num_metrics\n","        self.checkpoint_dir = checkpoint_dir\n","        self.learning_rate = learning_rate\n","        self.min_learning_rate = min_learning_rate \n","        self.build_model()\n","        log_dir = os.path.join(summary_dir)\n","        self.train_summary_writer = tf.summary.create_file_writer(log_dir)\n","\n","    def build_model(self):\n","        self.generator = S_Net_progressiveskip(num_metrics=self.num_metrics, structure_type='advanced')\n","\n","        #Learning rate decay for every 200 iterations\n","        self.lr_scheduler_fn =  tf.compat.v1.train.exponential_decay(self.learning_rate, self.step, 200, 0.1,  staircase=True)\n","        self.learning_rate = lambda : tf.maximum(self.min_learning_rate, self.lr_scheduler_fn())\n","\n","        self.generator_optimizer = tf.keras.optimizers.Adam( self.learning_rate )\n","\n","        \"\"\" saver \"\"\"\n","        self.ckpt = tf.train.Checkpoint(step=self.step,\n","                                        generator_optimizer=self.generator_optimizer,\n","                                        generator=self.generator,\n","                                        )\n","        self.save_manager = tf.train.CheckpointManager(self.ckpt, self.checkpoint_dir, max_to_keep=3)\n","        self.save  = lambda : self.save_manager.save(checkpoint_number=self.step) #exaple : model.save()\n","\n","\n","\n","    @tf.function\n","    def training(self, inputs):\n","        paired_input, paired_target = inputs\n","        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","            predictions = self.generator(paired_input)\n","            losses = [L1loss(paired_target, predictions[i]) for i in range(self.num_metrics)]\n","            total_loss = tf.reduce_mean(losses)\n","\n","        \"\"\" optimize \"\"\"\n","        params_gradients = self.generator.trainable_variables\n","        generator_gradients = gen_tape.gradient(total_loss, params_gradients)\n","        self.generator_optimizer.apply_gradients(zip(generator_gradients, params_gradients))\n","\n","        inputs_concat = tf.concat([paired_input, paired_target], axis=2)\n","        return_dicts = {\"inputs_concat\" :inputs_concat}\n","        return_dicts.update({'total_loss{}'.format(e) : l  for e,l in enumerate(losses)})\n","        return_dicts.update({'total_loss' : total_loss})\n","        return_dicts.update({'Predictions{}'.format(e) : tf.concat([paired_input,l,paired_target],axis=2)  for e,l in enumerate(predictions)})\n","        return return_dicts\n","\n","\n","\n","    def train_step(self,iterator, summary_name = \"train\", log_interval = 100):\n","        \"\"\" training \"\"\"\n","        result_logs_dict = self.training(iterator.__next__())\n","\n","        \"\"\" log summary \"\"\"\n","        if summary_name and self.step.numpy() % log_interval == 0:\n","            with self.train_summary_writer.as_default():\n","                for key, value in result_logs_dict.items():\n","                    value = value.numpy()\n","                    if len(value.shape) == 0:\n","                        tf.summary.scalar(\"{}_{}\".format(summary_name,key), value, step=self.step)\n","                    elif len(value.shape) in [3,4]:\n","                        tf.summary.image(\"{}_{}\".format(summary_name, key), denormalize(value), step=self.step)\n","\n","\n","        \"\"\" return log str \"\"\"\n","        log = \"Total_Loss : {} lr : {}\".format(result_logs_dict[\"total_loss\"], self.learning_rate().numpy())\n","        return log, [denormalize(result_logs_dict[\"Predictions{}\".format(i)].numpy() )for i in range(self.num_metrics)]\n","\n","\n","\n","\n","    # Typically, the test dataset is not large\n","    @tf.function\n","    def inference(self, input_image):\n","        return self.generator(input_image)\n","\n","    def test_step(self, test_dataset, summary_name = \"test\"):\n","        outputs = [[] for _ in range(self.num_metrics)]\n","        losses = [[] for _ in range(self.num_metrics)]\n","        PSNRs = [[] for _ in range(self.num_metrics)]\n","        SSIMs = [[] for _ in range(self.num_metrics)]\n","\n","        for input_image_test,label_image_test in test_dataset:\n","            predictions = self.inference(input_image_test)\n","            for e, pred in enumerate(predictions):\n","                losses[e].append(L1loss(label_image_test, pred).numpy())\n","                outputs[e].append(np.concatenate([input_image_test,pred.numpy(),label_image_test],axis=2))\n","                crop_pad = 8\n","                A = tf.split(tf.image.rgb_to_yuv(tf.convert_to_tensor(label_image_test[:,crop_pad:-crop_pad - 1, crop_pad:-crop_pad - 1] )), [1,2],-1)[0]\n","                B = tf.split(tf.image.rgb_to_yuv(tf.convert_to_tensor(pred.numpy()[:,crop_pad:-crop_pad - 1, crop_pad:-crop_pad - 1] )), [1,2],-1)[0]\n","                PSNRs[e].append(tf.image.psnr(A,B,1).numpy())\n","                SSIMs[e].append(tf.image.ssim(A,B,1).numpy())\n","\n","        \"\"\" log summary \"\"\"\n","        if summary_name and self.step.numpy() %100 == 0:\n","            with self.train_summary_writer.as_default():\n","                for e, output in enumerate(outputs):\n","                    tf.summary.image(\"{}_pred_{}_0\".format(summary_name,e), denormalize(output[0]), step=self.step)\n","                    tf.summary.image(\"{}_pred_{}_1\".format(summary_name,e), denormalize(output[1]), step=self.step)\n","                for e, loss in enumerate(losses):\n","                    tf.summary.scalar(\"{}_loss_{}\".format(summary_name, e),np.mean(loss), step=self.step)\n","                for e, PSNR in enumerate(PSNRs):\n","                    tf.summary.scalar(\"{}_psnr_{}\".format(summary_name, e),np.mean(PSNR), step=self.step)\n","                for e, SSIM in enumerate(SSIMs):\n","                    tf.summary.scalar(\"{}_ssim_{}\".format(summary_name, e),np.mean(SSIM), step=self.step)\n","\n","        \"\"\" return log str \"\"\"\n","        log = \"\\n\"\n","        for i in range(self.num_metrics):\n","            log += \"[output{}] loss = {}, psnr = {}, ssim = {}\\n\".format(i,np.mean(losses[i]),np.mean(PSNRs[i]),np.mean(SSIMs[i]))\n","        return log\n"]},{"cell_type":"code","execution_count":90,"metadata":{"executionInfo":{"elapsed":505,"status":"ok","timestamp":1661835137318,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"XRbsLK_g-P82"},"outputs":[],"source":["!rm -rf SNET*"]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":483,"status":"ok","timestamp":1661835137799,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"iV4B4pFKRXMY"},"outputs":[],"source":["!rm -rf /content/outputs"]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":437,"status":"ok","timestamp":1661835139501,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"f6Kk9sxPDiGu"},"outputs":[],"source":["!mkdir outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"0aq9eVNJIWS7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  f\"The initializer {self.__class__.__name__} is unseeded \"\n","100%|██████████| 191/191 [00:02<00:00, 87.81it/s]\n","100%|██████████| 19/19 [00:00<00:00, 52.71it/s]\n","WARNING:tensorflow:AutoGraph could not transform <bound method Model_Train.training of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fe6c57a6250>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module 'gast' has no attribute 'Constant'\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"name":"stdout","output_type":"stream","text":["WARNING: AutoGraph could not transform <bound method Model_Train.training of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fe6c57a6250>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module 'gast' has no attribute 'Constant'\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]}],"source":["import datetime\n","import time\n","\n","start = time.time()\n","time_now = datetime.datetime.now()\n","\n","\n","def generate_expname_automatically():\n","    name = \"SNET_%s_%02d_%02d_%02d_%02d_%02d\" % (\"assignment\",\n","            time_now.month, time_now.day, time_now.hour,\n","            time_now.minute, time_now.second)\n","    return name\n","\n","expname  = generate_expname_automatically()\n","checkpoint_dir = expname ; check_folder(\"./__outputs/checkpoints/\")\n","summary_dir = expname ; check_folder(\"./__outputs/summary/\")\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","\n","\"\"\" build model \"\"\"\n"," \n","num_metrics = 8\n","learning_rate = 0.0001\n","min_learning_rate = 0.000001\n","\n","model = Model_Train(summary_dir, num_metrics, checkpoint_dir, learning_rate, min_learning_rate)\n","\n","\"\"\" restore model \"\"\"\n","if False:\n","    model.ckpt.restore(config.restore_file)\n","\n","\n","\n","jpeg_quality = 30\n","patch_size = 48\n","batch_size = 16\n","data_path_train=\"/content/train/train_y\"\n","data_path_test=\"/content/validation/clean\"\n","\n","trainset_dispenser = Trainset_Dispenser(data_path_train,jpeg_quality, patch_size, batch_size)\n","testset_dispenser = Testset_Dispenser(data_path_test, jpeg_quality)\n","count = 0\n","steps = 0\n","while steps < 501: #manually stopping\n","    \"\"\" train \"\"\"\n","    log, output = model.train_step(trainset_dispenser, log_interval= 100)\n","    if model.step.numpy() % 1 == 0:\n","        print(\"[train] step:{} elapse:{} {}\".format(model.step.numpy(), time.time() - start, log))\n","\n","        #visualization\n","        output_concat = np.concatenate([output[i] for i in range(len(output))], axis=1)[0]\n","        output_concat = cv2.resize(output_concat,(output_concat.shape[1]*3,output_concat.shape[0]*3))\n","        cv2.imwrite('outputs/image_'+str(count)+'_.png', output_concat[...,::-1])\n","        count+=1\n","\n","    if model.step.numpy() % 100 == 0:\n","      log = model.test_step(testset_dispenser, summary_name=\"test\")\n","      print(\"[test] step:{} elapse:{} {}\".format(model.step.numpy(), time.time() - start, log))\n","\n","    \"\"\" save model \"\"\"\n","    if model.step.numpy() % 100 == 0:  save_path = model.save()\n","    model.step.assign_add(1)\n","    steps += 1"]},{"cell_type":"markdown","metadata":{"id":"4ecush3hgb8w"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10y2XrWx-kfQ"},"outputs":[],"source":["!rm -rf /content/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyeNNXwX7-2w"},"outputs":[],"source":["!mv SNET* weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmzVw8zLCGgW"},"outputs":[],"source":["num_metrics = 8\n","learning_rate = 0.0001\n","min_learning_rate = 0.000001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3XGhY1DO6eT"},"outputs":[],"source":["import os\n","checkpoint_dir = \"./__outputs/checkpoints/\"\n","summary_dir = \"./__outputs/summary/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkfJ5q5eZ_u3"},"outputs":[],"source":["def normalize(images):\n","    return (images.astype(np.float32)/255.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJsZyWNxnuLa"},"outputs":[],"source":["def denormalize(images):\n","    return np.clip(images*255, a_min=0, a_max=255).astype(np.uint8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":879,"status":"ok","timestamp":1661794716533,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"3SZCDKHmSDy8","outputId":"d9192aca-efc1-4b8b-9d95-75e9e1f030d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘preds’: File exists\n"]}],"source":["!mkdir preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8EtRluvWS9gW"},"outputs":[],"source":["!rm -rf /content/validation/down_grade/.ipynb_checkpoints"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aupH-sHMAxlJ"},"outputs":[],"source":["from google.colab.patches import cv2_imshow\n","import cv2\n","\n","def predict(image, model):\n","  image = np.array(image)\n","  ts = np.empty([image.shape[0], image.shape[1], 3], dtype=np.uint8)\n","  image = normalize(image)\n","  #cv2_imshow(cv2.cvtColor(ts, cv2.COLOR_BGR2RGB))\n","  for x in range(0,image.shape[0],48):\n","    for y in range(0,image.shape[1],48):\n","      im = image[x:x+48,y:y+48]\n","      im = np.expand_dims(im.astype(\"float32\"), axis=0)\n","      outs = model.generator(im)\n","      output = denormalize(outs[-1])\n","      ex = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n","      ts[x:x+48, y:y+48, :] = output\n","      #cv2_imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n","      #cv2.imwrite(\"outs\"+\"/\"+str(x)+str(y)+\".jpg\", cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n","      cv2_imshow(cv2.cvtColor(ts, cv2.COLOR_BGR2RGB))\n","  return ts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SNHshs86pi5x"},"outputs":[],"source":["from PIL import Image \n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1SJpW5659wlF_kFVdz9XFoZAA8Ei-Ed6n"},"id":"1J4Q6y9XRRj3","outputId":"ce39dd7f-8942-4433-8cd3-526864cf1ac5"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["model = Model_Train(summary_dir, num_metrics, checkpoint_dir, learning_rate, min_learning_rate)\n","model.ckpt.restore(\"/content/weights/ckpt-500\")\n","for i in os.listdir(\"/content/validation/down_grade/\"):\n","  image = Image.open(\"/content/validation/down_grade/\"+i).convert('RGB')\n","  image_clean = Image.open(\"/content/validation/clean/\"+i).convert('RGB')\n","  image_clean = np.array(image_clean)\n","  if image_clean.shape[0] % 48 != 0 or image_clean.shape[1] % 48 != 0:\n","    continue\n","  output = predict(image, model)\n","  im = Image.fromarray(output)\n","  print(\"\\n PSNR for original/reconstructed:\"+i,tf.image.psnr(image_clean, output, 255))\n","  print(\"\\n SSIM for original/reconstructed:\"+i,tf.image.ssim(tf.convert_to_tensor(image_clean),tf.convert_to_tensor(output),255))\n","  im.save(\"preds/\"+i)\n","  image.save(\"preds/dg_\"+i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qQtDvTi6Oi3"},"outputs":[],"source":["def predict(image, model):\n","  image = np.array(image)\n","  ts = np.empty([image.shape[0], image.shape[1], 3], dtype=image.dtype)\n","  for x in range(0,image.shape[0],48):\n","    for y in range(0,image.shape[1],48):\n","      im = image[x:x+48,y:y+48]\n","      ts[x:x+48, y:y+48, :] = im\n","  return ts\n","\n","for i in os.listdir(\"/content/validation/down_grade/\"):\n","  image = Image.open(\"/content/validation/down_grade/\"+i).convert('RGB')\n","  image_clean = Image.open(\"/content/validation/clean/\"+i).convert('RGB')\n","  image_clean = np.array(image_clean)\n","  if image_clean.shape[0] % 70 != 0 or image_clean.shape[1] % 70 != 0:\n","    continue\n","  output = predict(image, model)\n","  im = Image.fromarray(output.astype(np.uint8))\n","  display(im)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dy_kp14UxG-L"},"outputs":[],"source":["!zip -r outputs.zip outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660994174966,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"8Q4ctbUI9u4S","outputId":"6513753d-1c9d-4a86-fcdd-f84ac464809f"},"outputs":[{"data":{"text/plain":["(288, 288, 3)"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["image_clean.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4442,"status":"ok","timestamp":1661800358842,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"9NMPBXmcR0u-","outputId":"333bd74e-ab4d-49ee-e56f-8a1b73b41a39"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'FBCNN'...\n","remote: Enumerating objects: 201, done.\u001b[K\n","remote: Counting objects: 100% (27/27), done.\u001b[K\n","remote: Compressing objects: 100% (23/23), done.\u001b[K\n","remote: Total 201 (delta 20), reused 6 (delta 4), pack-reused 174\u001b[K\n","Receiving objects: 100% (201/201), 46.28 MiB | 18.14 MiB/s, done.\n","Resolving deltas: 100% (33/33), done.\n"]}],"source":["!git clone https://github.com/jiaxi-jiang/FBCNN.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1661800358844,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"I4PBYFZj9UaS","outputId":"46ef942b-acd8-441c-81ec-956462ac2dec"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/FBCNN\n"]}],"source":["%cd FBCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15753,"status":"ok","timestamp":1661801275348,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"oVH-M2nu9WAL","outputId":"987713c9-88c2-4a5d-832f-3a16461d92f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["export CUDA_VISIBLE_DEVICES=0\n","LogHandlers setup!\n","22-08-29 19:27:43.785 :   task: FBCNN-Color\n","  model: fbcnn\n","  gpu_ids: [0]\n","  n_channels: 3\n","  merge_bn: False\n","  merge_bn_startpoint: 40000000\n","  path:[\n","    root: deblocking\n","    pretrained_netG: None\n","    task: deblocking/FBCNN-Color\n","    log: deblocking/FBCNN-Color\n","    options: deblocking/FBCNN-Color/options\n","    models: deblocking/FBCNN-Color/models\n","    images: deblocking/FBCNN-Color/images\n","  ]\n","  datasets:[\n","    train:[\n","      name: train_dataset\n","      dataset_type: jpeg\n","      dataroot_H: /content/train/train_y\n","      dataroot_L: None\n","      H_size: 96\n","      dataloader_shuffle: True\n","      dataloader_num_workers: 16\n","      dataloader_batch_size: 16\n","      phase: train\n","      scale: 1\n","      n_channels: 3\n","    ]\n","    test:[\n","      name: test_dataset\n","      dataset_type: jpeg\n","      dataroot_H: /content/validation/clean\n","      dataroot_L: /content/validation/down_grade\n","      phase: test\n","      scale: 1\n","      n_channels: 3\n","    ]\n","  ]\n","  netG:[\n","    net_type: fbcnn\n","    in_nc: 3\n","    out_nc: 3\n","    nc: [64, 128, 256, 512]\n","    nb: 4\n","    act_mode: BR\n","    upsample_mode: convtranspose\n","    downsample_mode: strideconv\n","    init_type: orthogonal\n","    init_bn_type: uniform\n","    init_gain: 0.2\n","    scale: 1\n","  ]\n","  train:[\n","    G_lossfn_type: l1\n","    G_lossfn_weight: 1.0\n","    QF_lossfn_type: l1\n","    QF_lossfn_weight: 0.001\n","    G_optimizer_type: adam\n","    G_optimizer_lr: 2e-05\n","    G_optimizer_clipgrad: None\n","    G_scheduler_type: MultiStepLR\n","    G_scheduler_milestones: [200000, 400000, 1200000, 1600000, 1800000]\n","    G_scheduler_gamma: 0.5\n","    G_regularizer_orthstep: None\n","    G_regularizer_clipstep: None\n","    checkpoint_test: 2500\n","    checkpoint_save: 5000\n","    checkpoint_print: 500\n","  ]\n","  opt_path: options/train_fbcnn_color.json\n","  is_train: True\n","  scale: 1\n","\n","22-08-29 19:27:43.786 : Random seed: 1117\n","Dataset [DatasetJPEG - train_dataset] is created.\n","Dataset [DatasetJPEG - train_dataset] is created.\n","22-08-29 19:27:43.788 : Number of train images: 191, iters: 12\n","Dataset [DatasetJPEG - test_dataset] is created.\n","Dataset [DatasetJPEG - test_dataset] is created.\n","Initialization method [orthogonal + uniform], gain is [0.20]\n","Training model [ModelFBCNN] is created.\n","22-08-29 19:27:52.572 : \n","Networks name: FBCNN\n","Params number: 71941252\n","Net structure:\n","FBCNN(\n","  (m_head): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (m_down1): Sequential(\n","    (0): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (1): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (4): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n","  )\n","  (m_down2): Sequential(\n","    (0): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (1): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (4): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n","  )\n","  (m_down3): Sequential(\n","    (0): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (1): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (4): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n","  )\n","  (m_body_encoder): Sequential(\n","    (0): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (1): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (m_body_decoder): Sequential(\n","    (0): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (1): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (m_up3): ModuleList(\n","    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n","    (1): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (4): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (m_up2): ModuleList(\n","    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n","    (1): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (4): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (m_up1): ModuleList(\n","    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","    (1): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (4): QFAttention(\n","      (res): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (m_tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (qf_pred): Sequential(\n","    (0): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (1): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (3): ResBlock(\n","      (res): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (4): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (5): Flatten()\n","    (6): Linear(in_features=512, out_features=512, bias=True)\n","    (7): ReLU()\n","    (8): Linear(in_features=512, out_features=512, bias=True)\n","    (9): ReLU()\n","    (10): Linear(in_features=512, out_features=1, bias=True)\n","    (11): Sigmoid()\n","  )\n","  (qf_embed): Sequential(\n","    (0): Linear(in_features=1, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=512, bias=True)\n","    (5): ReLU()\n","  )\n","  (to_gamma_3): Sequential(\n","    (0): Linear(in_features=512, out_features=256, bias=True)\n","    (1): Sigmoid()\n","  )\n","  (to_beta_3): Sequential(\n","    (0): Linear(in_features=512, out_features=256, bias=True)\n","    (1): Tanh()\n","  )\n","  (to_gamma_2): Sequential(\n","    (0): Linear(in_features=512, out_features=128, bias=True)\n","    (1): Sigmoid()\n","  )\n","  (to_beta_2): Sequential(\n","    (0): Linear(in_features=512, out_features=128, bias=True)\n","    (1): Tanh()\n","  )\n","  (to_gamma_1): Sequential(\n","    (0): Linear(in_features=512, out_features=64, bias=True)\n","    (1): Sigmoid()\n","  )\n","  (to_beta_1): Sequential(\n","    (0): Linear(in_features=512, out_features=64, bias=True)\n","    (1): Tanh()\n","  )\n",")\n","\n","22-08-29 19:27:52.730 : \n"," |  mean  |  min   |  max   |  std   || param_name          \n"," | -0.000 | -0.082 |  0.076 |  0.025 || m_head.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_head.bias\n"," | -0.000 | -0.036 |  0.033 |  0.008 || m_down1.0.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.0.res.0.bias\n"," |  0.550 |  0.128 |  0.992 |  0.241 || m_down1.0.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.0.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.0.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down1.0.res.1.running_var\n"," | -0.000 | -0.038 |  0.032 |  0.008 || m_down1.0.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.0.res.3.bias\n"," |  0.000 | -0.031 |  0.039 |  0.008 || m_down1.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.1.res.0.bias\n"," |  0.564 |  0.156 |  0.996 |  0.261 || m_down1.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down1.1.res.1.running_var\n"," |  0.000 | -0.036 |  0.035 |  0.008 || m_down1.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.1.res.3.bias\n"," |  0.000 | -0.032 |  0.034 |  0.008 || m_down1.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.2.res.0.bias\n"," |  0.612 |  0.104 |  0.993 |  0.252 || m_down1.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down1.2.res.1.running_var\n"," |  0.000 | -0.033 |  0.036 |  0.008 || m_down1.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.2.res.3.bias\n"," | -0.000 | -0.036 |  0.035 |  0.008 || m_down1.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.3.res.0.bias\n"," |  0.588 |  0.162 |  0.999 |  0.265 || m_down1.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down1.3.res.1.running_var\n"," |  0.000 | -0.033 |  0.035 |  0.008 || m_down1.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.3.res.3.bias\n"," | -0.000 | -0.049 |  0.050 |  0.013 || m_down1.4.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down1.4.bias\n"," | -0.000 | -0.027 |  0.025 |  0.006 || m_down2.0.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.0.res.0.bias\n"," |  0.554 |  0.109 |  0.993 |  0.257 || m_down2.0.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.0.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.0.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down2.0.res.1.running_var\n"," |  0.000 | -0.026 |  0.026 |  0.006 || m_down2.0.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.0.res.3.bias\n"," |  0.000 | -0.025 |  0.025 |  0.006 || m_down2.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.1.res.0.bias\n"," |  0.520 |  0.100 |  0.998 |  0.270 || m_down2.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down2.1.res.1.running_var\n"," |  0.000 | -0.026 |  0.026 |  0.006 || m_down2.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.1.res.3.bias\n"," | -0.000 | -0.025 |  0.025 |  0.006 || m_down2.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.2.res.0.bias\n"," |  0.573 |  0.100 |  0.992 |  0.266 || m_down2.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down2.2.res.1.running_var\n"," | -0.000 | -0.029 |  0.027 |  0.006 || m_down2.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.2.res.3.bias\n"," |  0.000 | -0.025 |  0.027 |  0.006 || m_down2.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.3.res.0.bias\n"," |  0.557 |  0.111 |  0.983 |  0.257 || m_down2.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down2.3.res.1.running_var\n"," |  0.000 | -0.029 |  0.026 |  0.006 || m_down2.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.3.res.3.bias\n"," | -0.000 | -0.037 |  0.041 |  0.009 || m_down2.4.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down2.4.bias\n"," | -0.000 | -0.019 |  0.020 |  0.004 || m_down3.0.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.0.res.0.bias\n"," |  0.548 |  0.105 |  0.994 |  0.252 || m_down3.0.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.0.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.0.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down3.0.res.1.running_var\n"," | -0.000 | -0.020 |  0.022 |  0.004 || m_down3.0.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.0.res.3.bias\n"," | -0.000 | -0.021 |  0.021 |  0.004 || m_down3.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.1.res.0.bias\n"," |  0.548 |  0.100 |  0.997 |  0.255 || m_down3.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down3.1.res.1.running_var\n"," | -0.000 | -0.019 |  0.020 |  0.004 || m_down3.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.1.res.3.bias\n"," |  0.000 | -0.020 |  0.020 |  0.004 || m_down3.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.2.res.0.bias\n"," |  0.548 |  0.101 |  0.998 |  0.263 || m_down3.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down3.2.res.1.running_var\n"," | -0.000 | -0.021 |  0.019 |  0.004 || m_down3.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.2.res.3.bias\n"," |  0.000 | -0.019 |  0.022 |  0.004 || m_down3.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.3.res.0.bias\n"," |  0.567 |  0.108 |  0.999 |  0.261 || m_down3.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_down3.3.res.1.running_var\n"," |  0.000 | -0.020 |  0.020 |  0.004 || m_down3.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.3.res.3.bias\n"," |  0.000 | -0.028 |  0.029 |  0.006 || m_down3.4.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_down3.4.bias\n"," | -0.000 | -0.014 |  0.015 |  0.003 || m_body_encoder.0.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.0.res.0.bias\n"," |  0.542 |  0.103 |  0.998 |  0.248 || m_body_encoder.0.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.0.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.0.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_body_encoder.0.res.1.running_var\n"," |  0.000 | -0.015 |  0.016 |  0.003 || m_body_encoder.0.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.0.res.3.bias\n"," | -0.000 | -0.014 |  0.015 |  0.003 || m_body_encoder.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.1.res.0.bias\n"," |  0.552 |  0.103 |  0.996 |  0.246 || m_body_encoder.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_body_encoder.1.res.1.running_var\n"," |  0.000 | -0.016 |  0.016 |  0.003 || m_body_encoder.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.1.res.3.bias\n"," | -0.000 | -0.015 |  0.014 |  0.003 || m_body_encoder.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.2.res.0.bias\n"," |  0.554 |  0.102 |  0.998 |  0.262 || m_body_encoder.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_body_encoder.2.res.1.running_var\n"," |  0.000 | -0.014 |  0.015 |  0.003 || m_body_encoder.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.2.res.3.bias\n"," | -0.000 | -0.014 |  0.015 |  0.003 || m_body_encoder.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.3.res.0.bias\n"," |  0.555 |  0.102 |  0.999 |  0.253 || m_body_encoder.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_body_encoder.3.res.1.running_var\n"," | -0.000 | -0.016 |  0.014 |  0.003 || m_body_encoder.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_encoder.3.res.3.bias\n"," | -0.000 | -0.014 |  0.016 |  0.003 || m_body_decoder.0.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.0.res.0.bias\n"," |  0.554 |  0.100 |  0.999 |  0.260 || m_body_decoder.0.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.0.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.0.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_body_decoder.0.res.1.running_var\n"," |  0.000 | -0.014 |  0.015 |  0.003 || m_body_decoder.0.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.0.res.3.bias\n"," |  0.000 | -0.016 |  0.014 |  0.003 || m_body_decoder.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.1.res.0.bias\n"," |  0.544 |  0.100 |  0.999 |  0.265 || m_body_decoder.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_body_decoder.1.res.1.running_var\n"," |  0.000 | -0.015 |  0.015 |  0.003 || m_body_decoder.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.1.res.3.bias\n"," |  0.000 | -0.014 |  0.014 |  0.003 || m_body_decoder.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.2.res.0.bias\n"," |  0.557 |  0.101 |  0.999 |  0.263 || m_body_decoder.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_body_decoder.2.res.1.running_var\n"," |  0.000 | -0.015 |  0.016 |  0.003 || m_body_decoder.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.2.res.3.bias\n"," |  0.000 | -0.016 |  0.017 |  0.003 || m_body_decoder.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.3.res.0.bias\n"," |  0.568 |  0.100 |  0.999 |  0.259 || m_body_decoder.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_body_decoder.3.res.1.running_var\n"," | -0.000 | -0.016 |  0.014 |  0.003 || m_body_decoder.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_body_decoder.3.res.3.bias\n"," | -0.000 | -0.029 |  0.032 |  0.006 || m_up3.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.0.bias\n"," |  0.000 | -0.019 |  0.021 |  0.004 || m_up3.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.1.res.0.bias\n"," |  0.581 |  0.126 |  1.000 |  0.251 || m_up3.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up3.1.res.1.running_var\n"," |  0.000 | -0.019 |  0.020 |  0.004 || m_up3.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.1.res.3.bias\n"," |  0.000 | -0.020 |  0.021 |  0.004 || m_up3.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.2.res.0.bias\n"," |  0.584 |  0.103 |  0.997 |  0.265 || m_up3.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up3.2.res.1.running_var\n"," |  0.000 | -0.019 |  0.020 |  0.004 || m_up3.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.2.res.3.bias\n"," |  0.000 | -0.019 |  0.021 |  0.004 || m_up3.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.3.res.0.bias\n"," |  0.564 |  0.112 |  1.000 |  0.257 || m_up3.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up3.3.res.1.running_var\n"," | -0.000 | -0.020 |  0.020 |  0.004 || m_up3.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.3.res.3.bias\n"," |  0.000 | -0.021 |  0.021 |  0.004 || m_up3.4.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.4.res.0.bias\n"," |  0.555 |  0.103 |  0.990 |  0.252 || m_up3.4.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.4.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.4.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up3.4.res.1.running_var\n"," |  0.000 | -0.018 |  0.018 |  0.004 || m_up3.4.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up3.4.res.3.bias\n"," | -0.000 | -0.039 |  0.036 |  0.009 || m_up2.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.0.bias\n"," |  0.000 | -0.026 |  0.027 |  0.006 || m_up2.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.1.res.0.bias\n"," |  0.525 |  0.106 |  0.996 |  0.262 || m_up2.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up2.1.res.1.running_var\n"," |  0.000 | -0.027 |  0.026 |  0.006 || m_up2.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.1.res.3.bias\n"," |  0.000 | -0.028 |  0.027 |  0.006 || m_up2.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.2.res.0.bias\n"," |  0.512 |  0.101 |  0.998 |  0.273 || m_up2.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up2.2.res.1.running_var\n"," | -0.000 | -0.025 |  0.026 |  0.006 || m_up2.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.2.res.3.bias\n"," | -0.000 | -0.025 |  0.026 |  0.006 || m_up2.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.3.res.0.bias\n"," |  0.610 |  0.113 |  0.992 |  0.244 || m_up2.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up2.3.res.1.running_var\n"," | -0.000 | -0.025 |  0.025 |  0.006 || m_up2.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.3.res.3.bias\n"," |  0.000 | -0.028 |  0.030 |  0.006 || m_up2.4.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.4.res.0.bias\n"," |  0.554 |  0.101 |  0.989 |  0.261 || m_up2.4.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.4.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.4.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up2.4.res.1.running_var\n"," | -0.000 | -0.027 |  0.026 |  0.006 || m_up2.4.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up2.4.res.3.bias\n"," |  0.000 | -0.050 |  0.047 |  0.012 || m_up1.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.0.bias\n"," |  0.000 | -0.035 |  0.033 |  0.008 || m_up1.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.1.res.0.bias\n"," |  0.609 |  0.114 |  0.995 |  0.238 || m_up1.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up1.1.res.1.running_var\n"," |  0.000 | -0.031 |  0.032 |  0.008 || m_up1.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.1.res.3.bias\n"," | -0.000 | -0.036 |  0.037 |  0.008 || m_up1.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.2.res.0.bias\n"," |  0.555 |  0.112 |  0.997 |  0.258 || m_up1.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up1.2.res.1.running_var\n"," | -0.000 | -0.031 |  0.033 |  0.008 || m_up1.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.2.res.3.bias\n"," | -0.000 | -0.032 |  0.034 |  0.008 || m_up1.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.3.res.0.bias\n"," |  0.618 |  0.105 |  0.986 |  0.274 || m_up1.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up1.3.res.1.running_var\n"," |  0.000 | -0.035 |  0.035 |  0.008 || m_up1.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.3.res.3.bias\n"," |  0.000 | -0.037 |  0.035 |  0.008 || m_up1.4.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.4.res.0.bias\n"," |  0.478 |  0.107 |  0.957 |  0.241 || m_up1.4.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.4.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.4.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || m_up1.4.res.1.running_var\n"," |  0.000 | -0.033 |  0.036 |  0.008 || m_up1.4.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_up1.4.res.3.bias\n"," | -0.000 | -0.031 |  0.029 |  0.008 || m_tail.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || m_tail.bias\n"," |  0.000 | -0.015 |  0.015 |  0.003 || qf_pred.0.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.0.res.0.bias\n"," |  0.547 |  0.101 |  1.000 |  0.253 || qf_pred.0.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.0.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.0.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || qf_pred.0.res.1.running_var\n"," | -0.000 | -0.016 |  0.017 |  0.003 || qf_pred.0.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.0.res.3.bias\n"," |  0.000 | -0.014 |  0.014 |  0.003 || qf_pred.1.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.1.res.0.bias\n"," |  0.546 |  0.102 |  0.999 |  0.267 || qf_pred.1.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.1.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.1.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || qf_pred.1.res.1.running_var\n"," | -0.000 | -0.016 |  0.014 |  0.003 || qf_pred.1.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.1.res.3.bias\n"," | -0.000 | -0.015 |  0.016 |  0.003 || qf_pred.2.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.2.res.0.bias\n"," |  0.548 |  0.101 |  1.000 |  0.257 || qf_pred.2.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.2.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.2.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || qf_pred.2.res.1.running_var\n"," | -0.000 | -0.014 |  0.014 |  0.003 || qf_pred.2.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.2.res.3.bias\n"," | -0.000 | -0.015 |  0.015 |  0.003 || qf_pred.3.res.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.3.res.0.bias\n"," |  0.537 |  0.100 |  1.000 |  0.262 || qf_pred.3.res.1.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.3.res.1.bias\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.3.res.1.running_mean\n"," |  1.000 |  1.000 |  1.000 |  0.000 || qf_pred.3.res.1.running_var\n"," | -0.000 | -0.015 |  0.015 |  0.003 || qf_pred.3.res.3.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.3.res.3.bias\n"," |  0.000 | -0.042 |  0.039 |  0.009 || qf_pred.6.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.6.bias\n"," |  0.000 | -0.043 |  0.040 |  0.009 || qf_pred.8.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_pred.8.bias\n"," | -0.001 | -0.023 |  0.026 |  0.009 || qf_pred.10.weight\n"," |  0.000 |  0.000 |  0.000 |    nan || qf_pred.10.bias\n"," |  0.000 | -0.024 |  0.029 |  0.009 || qf_embed.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_embed.0.bias\n"," |  0.000 | -0.040 |  0.039 |  0.009 || qf_embed.2.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_embed.2.bias\n"," | -0.000 | -0.040 |  0.037 |  0.009 || qf_embed.4.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || qf_embed.4.bias\n"," | -0.000 | -0.040 |  0.038 |  0.009 || to_gamma_3.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || to_gamma_3.0.bias\n"," |  0.000 | -0.037 |  0.038 |  0.009 || to_beta_3.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || to_beta_3.0.bias\n"," |  0.000 | -0.037 |  0.040 |  0.009 || to_gamma_2.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || to_gamma_2.0.bias\n"," | -0.000 | -0.036 |  0.037 |  0.009 || to_beta_2.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || to_beta_2.0.bias\n"," |  0.000 | -0.036 |  0.036 |  0.009 || to_gamma_1.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || to_gamma_1.0.bias\n"," | -0.000 | -0.032 |  0.035 |  0.009 || to_beta_1.0.weight\n"," |  0.000 |  0.000 |  0.000 |  0.000 || to_beta_1.0.bias\n","\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","Traceback (most recent call last):\n","  File \"main_train_fbcnn.py\", line 252, in <module>\n","    main()\n","  File \"main_train_fbcnn.py\", line 130, in main\n","    for i, train_data in enumerate(train_loader):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 801, in __next__\n","    return self._process_data(data)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 846, in _process_data\n","    data.reraise()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 369, in reraise\n","    raise self.exc_type(msg)\n","RuntimeError: Caught RuntimeError in DataLoader worker process 8.\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n","    data = fetcher.fetch(index)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n","    return self.collate_fn(data)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 75, in default_collate\n","    return {key: default_collate([d[key] for d in batch]) for key in elem}\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 75, in <dictcomp>\n","    return {key: default_collate([d[key] for d in batch]) for key in elem}\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 56, in default_collate\n","    return torch.stack(batch, 0, out=out)\n","RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 96 and 78 in dimension 2 at /pytorch/aten/src/TH/generic/THTensor.cpp:689\n","\n"]}],"source":["!python main_train_fbcnn.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78206,"status":"ok","timestamp":1661801036310,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"URIAkhEc-hzA","outputId":"bc6f3e13-7bcc-4d81-9361-d87000fc11d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/nightly/cu100/torch_nightly.html\n","Collecting torch_nightly\n","  Downloading https://download.pytorch.org/whl/nightly/cu100/torch_nightly-1.2.0.dev20190805-cp37-cp37m-linux_x86_64.whl (790.0 MB)\n","\u001b[K     |████████████████████████████████| 790.0 MB 20 kB/s \n","\u001b[?25hInstalling collected packages: torch-nightly\n","Successfully installed torch-nightly-1.2.0.dev20190805\n"]}],"source":["!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu100/torch_nightly.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107881,"status":"ok","timestamp":1661801259632,"user":{"displayName":"Rahul Mangalampalli","userId":"04182817747895603267"},"user_tz":-330},"id":"ieHCUuaRDkFG","outputId":"0cdda203-85e5-46a8-d971-d507227e9e7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: torchvision 0.13.1+cu113\n","Uninstalling torchvision-0.13.1+cu113:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/torchvision-0.13.1+cu113.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libcudart.053364c0.so.11.0\n","    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n","    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libnvjpeg.90286a3c.so.11\n","    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n","    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libz.1328edc3.so.1\n","    /usr/local/lib/python3.7/dist-packages/torchvision/*\n","Proceed (y/n)? y\n","  Successfully uninstalled torchvision-0.13.1+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torchvision==0.4.0\n","  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 49.2 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (7.1.2)\n","Collecting torch==1.2.0\n","  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n","\u001b[K     |████████████████████████████████| 663.1 MB 1.8 kB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (1.21.6)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.2.0+cu92 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.2.0+cu92 which is incompatible.\n","fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.2.0+cu92 which is incompatible.\n","fastai 2.7.9 requires torchvision>=0.8.2, but you have torchvision 0.4.0+cu92 which is incompatible.\u001b[0m\n","Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"]}],"source":["!pip uninstall torchvision\n","!pip install torchvision==0.4.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaOu8YuIERKu"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOjsgYqM+vWKUIHL9Wbo/wX","collapsed_sections":[],"name":"Tensorflow_artifact_removal_exp.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
